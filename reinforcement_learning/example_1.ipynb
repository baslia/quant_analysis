{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T11:57:17.717798Z",
     "start_time": "2024-03-07T11:57:15.822054Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (backtest.py, line 180)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3548\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0;36m  Cell \u001B[0;32mIn[2], line 7\u001B[0;36m\n\u001B[0;31m    import backtest as twp\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m~/Library/CloudStorage/OneDrive-NielsenIQ/PycharmProjects/quant_analysis/reinforcement_learning/backtest.py:180\u001B[0;36m\u001B[0m\n\u001B[0;31m    print '\\r',self,\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "np.random.seed(11)  # for reproducibility\n",
    "np.set_printoptions(precision=5, suppress=True, linewidth=150)\n",
    "\n",
    "import pandas as pd\n",
    "import backtest as twp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Load data\n",
    "def load_data():\n",
    "    price = np.arange(200/10.0) #linearly increasing prices\n",
    "    return price"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d093a77f8a6c1ebf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Initialize first state, all items are placed deterministically\n",
    "def init_state(data):\n",
    "    \n",
    "    close = data\n",
    "    diff = np.diff(data)\n",
    "    diff = np.insert(diff, 0, 0)\n",
    "    \n",
    "    #--- Preprocess data\n",
    "    xdata = np.column_stack((close, diff))\n",
    "    xdata = np.nan_to_num(xdata)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    xdata = scaler.fit_transform(xdata)\n",
    "    \n",
    "    state = xdata[0:1, :]\n",
    "    return state, xdata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e72806613da1bea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Take Action\n",
    "def take_action(state, xdata, action, signal, time_step):\n",
    "    #this should generate a list of trade signals that at evaluation time are fed to the backtester\n",
    "    #the backtester should get a list of trade signals and a list of price data for the assett\n",
    "    \n",
    "    #make necessary adjustments to state and then return it\n",
    "    time_step += 1\n",
    "    \n",
    "    #if the current iteration is the last state (\"terminal state\") then set terminal_state to 1\n",
    "    if time_step == xdata.shape[0]:\n",
    "        state = xdata[time_step-1:time_step, :]\n",
    "        terminal_state = 1\n",
    "        signal.loc[time_step] = 0\n",
    "        return state, time_step, signal, terminal_state\n",
    "\n",
    "    #move the market data window one step forward\n",
    "    state = xdata[time_step-1:time_step, :]\n",
    "    #take action\n",
    "    if action != 0:\n",
    "        if action == 1:\n",
    "            signal.loc[time_step] = 100\n",
    "        elif action == 2:\n",
    "            signal.loc[time_step] = -100\n",
    "        elif action == 3:\n",
    "            signal.loc[time_step] = 0\n",
    "    terminal_state = 0\n",
    "\n",
    "    return state, time_step, signal, terminal_state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5020f74ead06516c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Get Reward, the reward is returned at the end of an episode\n",
    "def get_reward(new_state, time_step, action, xdata, signal, terminal_state, epoch=0):\n",
    "    reward = 0\n",
    "    signal.fillna(value=0, inplace=True)\n",
    "    if terminal_state == 0:\n",
    "        #get reward for the most current action\n",
    "        if signal[time_step] != signal[time_step-1] and terminal_state == 0:\n",
    "            i=1\n",
    "            while signal[time_step-i] == signal[time_step-1-i] and time_step - 1 - i > 0:\n",
    "                i += 1\n",
    "            reward = (xdata[time_step-1, 0] - xdata[time_step - i-1, 0]) * signal[time_step - 1]*-100 + i*np.abs(signal[time_step - 1])/10.0\n",
    "        if signal[time_step] == 0 and signal[time_step - 1] == 0:\n",
    "            reward -= 10\n",
    "\n",
    "    #calculate the reward for all actions if the last iteration in set\n",
    "    if terminal_state == 1:\n",
    "        #run backtest, send list of trade signals and asset data to backtest function\n",
    "        bt = twp.Backtest(pd.Series(data=[x[0] for x in xdata]), signal, signalType='shares')\n",
    "        reward = bt.pnl.iloc[-1]\n",
    "\n",
    "    return reward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T11:57:18.055286Z",
     "start_time": "2024-03-07T11:57:18.050847Z"
    }
   },
   "id": "f89c76cc1925bd01",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_Q(eval_data, eval_model):\n",
    "    #This function is used to evaluate the perofrmance of the system each epoch, without the influence of epsilon and random actions\n",
    "    signal = pd.Series(index=np.arange(len(eval_data)))\n",
    "    state, xdata = init_state(eval_data)\n",
    "    status = 1\n",
    "    terminal_state = 0\n",
    "    time_step = 1\n",
    "    while(status == 1):\n",
    "        #We start in state S\n",
    "        #Run the Q function on S to get predicted reward values on all the possible actions\n",
    "        qval = eval_model.predict(state.reshape(1,2), batch_size=1)\n",
    "        action = (np.argmax(qval))\n",
    "        #Take action, observe new state S'\n",
    "        new_state, time_step, signal, terminal_state = take_action(state, xdata, action, signal, time_step)\n",
    "        #Observe reward\n",
    "        eval_reward = get_reward(new_state, time_step, action, xdata, signal, terminal_state, i)\n",
    "        state = new_state\n",
    "        if terminal_state == 1: #terminal state\n",
    "            status = 0\n",
    "    return eval_reward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T11:57:18.669194Z",
     "start_time": "2024-03-07T11:57:18.666119Z"
    }
   },
   "id": "af27f7d702b78ddd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.core'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#This neural network is the the Q-function, run it like this:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#model.predict(state.reshape(1,64), batch_size=1)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout, Activation\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RMSprop\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m Sequential()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras.layers.core'"
     ]
    }
   ],
   "source": [
    "#This neural network is the Q-function, run it like this:\n",
    "#model.predict(state.reshape(1,64), batch_size=1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, init='lecun_uniform', input_shape=(2,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2)) I'm not using dropout in this example\n",
    "\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='mse', optimizer=rms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T11:57:54.244559Z",
     "start_time": "2024-03-07T11:57:42.847432Z"
    }
   },
   "id": "185fda39bc7d19df",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a643c3fefd482836"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
