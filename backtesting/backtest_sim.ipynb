{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.015302Z",
     "start_time": "2023-06-19T21:50:40.929434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports and set up\n",
    "\n",
    "# Start by importing NumPy and vectorbt. Youâ€™ll use SciPy to test the statistical significance of the results.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import vectorbt as vbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Then create an array of moving average windows to test and download price data.\n",
    "\n",
    "windows = np.arange(10, 50)\n",
    "\n",
    "price = vbt.YFData.download('AAPL').get('Close')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.536443Z",
     "start_time": "2023-06-19T21:50:46.023865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Build the functions\n",
    "\n",
    "# Create the data splits for the walk-forward optimization.\n",
    "\n",
    "(in_price, in_indexes), (out_price, out_indexes) = price.vbt.rolling_split(\n",
    "    n=30,\n",
    "    window_len=365 * 2,\n",
    "    set_lens=(180,),\n",
    "    left_to_right=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.551386Z",
     "start_time": "2023-06-19T21:50:46.536983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# This code segments the prices into 30 splits, each two years long, and reserves 180 days for the test.\n",
    "\n",
    "# Now create the functions that run the backtest.\n",
    "\n",
    "def simulate_all_params(price, windows, **kwargs):\n",
    "    fast_ma, slow_ma = vbt.MA.run_combs(\n",
    "        price, windows, r=2, short_names=[\"fast\", \"slow\"]\n",
    "    )\n",
    "    entries = fast_ma.ma_crossed_above(slow_ma)\n",
    "    exits = fast_ma.ma_crossed_below(slow_ma)\n",
    "\n",
    "    pf = vbt.Portfolio.from_signals(price, entries, exits, **kwargs)\n",
    "    return pf.sharpe_ratio()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.556454Z",
     "start_time": "2023-06-19T21:50:46.554065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# This function builds two moving averages for each window you pass in.\n",
    "\n",
    "# Then it creates DataFrames showing where the fast-moving average crosses above the slow-moving average. These are the trade entries. It does the opposite for the trade exits.\n",
    "\n",
    "# After the backtest is run, the function returns the Sharpe ratio.\n",
    "\n",
    "# Next, you need to figure out the combination of windows that maximizes the Sharpe ratio.\n",
    "\n",
    "def get_best_index(performance, higher_better=True):\n",
    "    if higher_better:\n",
    "        return performance[performance.groupby('split_idx').idxmax()].index\n",
    "    return performance[performance.groupby('split_idx').idxmin()].index\n",
    "\n",
    "def get_best_params(best_index, level_name):\n",
    "    return best_index.get_level_values(level_name).to_numpy()\n",
    "# The first function returns the indexes in the DataFrame for the windows in each data split that maximizes the Sharpe ratio. The second function returns the window values."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.566595Z",
     "start_time": "2023-06-19T21:50:46.558564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Finally, create a function that runs the backtest with the windows that maximize the Sharpe ratio.\n",
    "\n",
    "def simulate_best_params(price, best_fast_windows, best_slow_windows, **kwargs):\n",
    "\n",
    "    fast_ma = vbt.MA.run(price, window=best_fast_windows, per_column=True)\n",
    "    slow_ma = vbt.MA.run(price, window=best_slow_windows, per_column=True)\n",
    "\n",
    "    entries = fast_ma.ma_crossed_above(slow_ma)\n",
    "    exits = fast_ma.ma_crossed_below(slow_ma)\n",
    "\n",
    "    pf = vbt.Portfolio.from_signals(price, entries, exits, **kwargs)\n",
    "    return pf.sharpe_ratio()\n",
    "# This function creates the moving average values that maximize the Sharpe ratio, runs the backtest, and returns the Sharpe ratio.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:50:46.567559Z",
     "start_time": "2023-06-19T21:50:46.563481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "\n",
    "# Start by optimizing the moving average windows on the in-sample data.\n",
    "\n",
    "in_sharpe = simulate_all_params(\n",
    "    in_price,\n",
    "    windows,\n",
    "    direction=\"both\",\n",
    "    freq=\"d\"\n",
    ")\n",
    "# The result is a DataFrame that has the Sharpe ratio for the best combination of windows for each split.\n",
    "\n",
    "# Now you can get the optimized windows and test them with out-of-sample data.\n",
    "\n",
    "in_best_index = get_best_index(in_sharpe)\n",
    "\n",
    "in_best_fast_windows = get_best_params(\n",
    "    in_best_index,\n",
    "    'fast_window'\n",
    ")\n",
    "in_best_slow_windows = get_best_params(\n",
    "    in_best_index,\n",
    "    'slow_window'\n",
    ")\n",
    "in_best_window_pairs = np.array(\n",
    "    list(\n",
    "        zip(\n",
    "            in_best_fast_windows,\n",
    "            in_best_slow_windows\n",
    "        )\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:51:18.573590Z",
     "start_time": "2023-06-19T21:51:06.152402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "ma_window  ma_window  split_idx\n15         30         0            2.934171\n17         19         1           -1.182685\n19         22         2            1.825433\n35         36         3           -0.379473\n10         11         4           -2.212113\n11         13         5           -0.823432\n17         18         6           -2.268702\n19         20         7            0.150229\n13         15         8            1.595456\n10         24         9            0.779228\n11         32         10           0.402868\n10         45         11           0.483384\n26         32         12          -0.557833\n48         49         13           0.291812\n13         15         14          -0.564042\n29         36         15          -2.069703\n12         14         16          -0.695318\n35         36         17           2.460269\n31         32         18           0.063564\n14         49         19                inf\n38         49         20           2.714624\n41         44         21           0.777409\n16         30         22           0.578244\n32         33         23           0.503056\n31         41         24          -1.239742\n10         17         25           0.920647\n48         49         26           2.037162\n20         26         27           1.777259\n18         20         28          -0.423397\n10         14         29           1.680857\nName: sharpe_ratio, dtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running this code gives you the parameter values for the fast-moving average and slow-moving average you can test with the out-of-sample data.\n",
    "\n",
    "out_test_sharpe = simulate_best_params(\n",
    "    out_price,\n",
    "    in_best_fast_windows,\n",
    "    in_best_slow_windows,\n",
    "    direction=\"both\",\n",
    "    freq=\"d\"\n",
    ")\n",
    "# The result is a DataFrame that has the Sharpe ratio for the backtest using out-of-sample test data and the window values that optimize the Sharpe ratio from the in-sample data.\n",
    "out_test_sharpe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:52:16.694042Z",
     "start_time": "2023-06-19T21:52:16.673401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.9/site-packages/scipy/stats/_stats_py.py:1182: RuntimeWarning: invalid value encountered in subtract\n",
      "  a_zero_mean = a - mean\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "\n",
    "# The whole point of this analysis is to understand if the parameters you fit on the in-sample data can be used in real life to make money.\n",
    "\n",
    "# The most common issue in backtesting is overfitting to random data. (Especially when using technical analysis.)\n",
    "\n",
    "# You can run a simple t-test to understand if the out-of-sample Sharpe ratio is statistically greater than the in-sample Sharpe ratio. If it were, it would give you some measure of confidence that you did not overfit to random data.\n",
    "\n",
    "in_sample_best = in_sharpe[in_best_index].values\n",
    "out_sample_test = out_test_sharpe.values\n",
    "\n",
    "t, p = stats.ttest_ind(\n",
    "    a=out_sample_test,\n",
    "    b=in_sample_best,\n",
    "    alternative=\"greater\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:52:26.459632Z",
     "start_time": "2023-06-19T21:52:26.450743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.28468017, 2.37503945, 1.3664512 , 2.78876011, 1.46241364,\n       1.04446549, 2.2527809 , 2.28616777, 1.78566952, 1.50841107,\n       0.97898887, 1.41685958, 1.36869151, 1.23858968, 1.45397882,\n       1.33697608, 1.39323022, 2.65541281, 1.74225941, 1.65555823,\n       3.00510862, 1.49608238, 2.05083162, 1.83479291, 1.70201641,\n       1.33762371, 1.12723992, 2.04648867, 2.20829972, 0.95648917])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_best"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:52:48.712061Z",
     "start_time": "2023-06-19T21:52:48.706529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.93417072, -1.1826848 ,  1.82543294, -0.3794729 , -2.21211286,\n       -0.82343175, -2.26870223,  0.15022907,  1.59545584,  0.77922779,\n        0.40286777,  0.48338428, -0.55783331,  0.29181243, -0.564042  ,\n       -2.06970252, -0.69531819,  2.46026949,  0.06356449,         inf,\n        2.71462436,  0.77740906,  0.57824441,  0.50305597, -1.23974177,\n        0.9206466 ,  2.03716192,  1.77725919, -0.42339654,  1.68085737])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sample_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T21:52:55.402092Z",
     "start_time": "2023-06-19T21:52:55.397597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
