{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-clothing",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-03T04:57:54.198152Z",
     "iopub.status.busy": "2021-04-03T04:57:54.197005Z",
     "iopub.status.idle": "2021-04-03T05:00:42.175245Z",
     "shell.execute_reply": "2021-04-03T05:00:42.173533Z"
    },
    "papermill": {
     "duration": 167.993805,
     "end_time": "2021-04-03T05:00:42.175556",
     "exception": false,
     "start_time": "2021-04-03T04:57:54.181751",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-17T17:46:53.355914Z",
     "start_time": "2024-02-17T17:46:32.162502Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 12\u001B[0m\n\u001B[1;32m      6\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# from env.EnvMultipleStock_train import StockEnvTrain\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# from env.EnvMultipleStock_validation import StockEnvValidation\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# from env.EnvMultipleStock_trade import StockEnvTrade\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GAIL, SAC\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ACER\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PPO2\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/stable_baselines/__init__.py:7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01macer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ACER\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01macktr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ACKTR\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeepq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DQN\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mher\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HER\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mppo2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PPO2\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/stable_baselines/deepq/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeepq\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpolicies\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MlpPolicy, CnnPolicy, LnMlpPolicy, LnCnnPolicy\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeepq\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbuild_graph\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_act, build_train  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstable_baselines\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeepq\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdqn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DQN\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/stable_baselines/deepq/policies.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf_layers\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspaces\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Discrete\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# from env.EnvMultipleStock_train import StockEnvTrain\n",
    "# from env.EnvMultipleStock_validation import StockEnvValidation\n",
    "# from env.EnvMultipleStock_trade import StockEnvTrade\n",
    "\n",
    "from stable_baselines import GAIL, SAC\n",
    "from stable_baselines import ACER\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines import DDPG\n",
    "from stable_baselines import TD3\n",
    "\n",
    "from stable_baselines.ddpg.policies import DDPGPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-calcium",
   "metadata": {
    "papermill": {
     "duration": 0.035776,
     "end_time": "2021-04-03T05:00:42.246099",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.210323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"dataset\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Dataset\n",
    "        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "registered-specialist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.319007Z",
     "iopub.status.busy": "2021-04-03T05:00:42.318274Z",
     "iopub.status.idle": "2021-04-03T05:00:42.766545Z",
     "shell.execute_reply": "2021-04-03T05:00:42.765961Z"
    },
    "papermill": {
     "duration": 0.486202,
     "end_time": "2021-04-03T05:00:42.766718",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.280516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datadate</th>\n",
       "      <th>tic</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cci</th>\n",
       "      <th>adx</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20090102</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>12.964286</td>\n",
       "      <td>12.268571</td>\n",
       "      <td>13.005714</td>\n",
       "      <td>12.165714</td>\n",
       "      <td>26641980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20090102</td>\n",
       "      <td>AXP</td>\n",
       "      <td>19.330000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>10955620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20090102</td>\n",
       "      <td>BA</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>42.800000</td>\n",
       "      <td>45.560000</td>\n",
       "      <td>42.780000</td>\n",
       "      <td>7010171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20090102</td>\n",
       "      <td>CAT</td>\n",
       "      <td>46.910000</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.710000</td>\n",
       "      <td>7116726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20090102</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.960000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>40977480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  datadate   tic      adjcp       open       high        low  \\\n",
       "0           0  20090102  AAPL  12.964286  12.268571  13.005714  12.165714   \n",
       "1           1  20090102   AXP  19.330000  18.570000  19.520000  18.400000   \n",
       "2           2  20090102    BA  45.250000  42.800000  45.560000  42.780000   \n",
       "3           3  20090102   CAT  46.910000  44.910000  46.980000  44.710000   \n",
       "4           4  20090102  CSCO  16.960000  16.410000  17.000000  16.250000   \n",
       "\n",
       "       volume  macd    rsi        cci    adx  turbulence  \n",
       "0  26641980.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "1  10955620.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "2   7010171.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "3   7116726.0   0.0    0.0  66.666667  100.0         0.0  \n",
       "4  40977480.0   0.0  100.0  66.666667  100.0         0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/kaggle/input/trading/trading.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understanding-fields",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.841646Z",
     "iopub.status.busy": "2021-04-03T05:00:42.841006Z",
     "iopub.status.idle": "2021-04-03T05:00:42.845211Z",
     "shell.execute_reply": "2021-04-03T05:00:42.844583Z"
    },
    "papermill": {
     "duration": 0.043923,
     "end_time": "2021-04-03T05:00:42.845383",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.801460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63\n",
    "validation_window = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cheap-madison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.927058Z",
     "iopub.status.busy": "2021-04-03T05:00:42.925790Z",
     "iopub.status.idle": "2021-04-03T05:00:42.938471Z",
     "shell.execute_reply": "2021-04-03T05:00:42.937753Z"
    },
    "papermill": {
     "duration": 0.055925,
     "end_time": "2021-04-03T05:00:42.938636",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.882711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n"
     ]
    }
   ],
   "source": [
    "unique_trade_date = df[(df.datadate > 20151001)&(df.datadate <= 20200707)].datadate.unique()\n",
    "print(unique_trade_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-lease",
   "metadata": {
    "papermill": {
     "duration": 0.036451,
     "end_time": "2021-04-03T05:00:43.010626",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.974175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"stable\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Stable Baseline\n",
    "        <a class=\"anchor-link\" href=\"#stable\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "senior-dispatch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.101017Z",
     "iopub.status.busy": "2021-04-03T05:00:43.100132Z",
     "iopub.status.idle": "2021-04-03T05:00:43.103435Z",
     "shell.execute_reply": "2021-04-03T05:00:43.102911Z"
    },
    "papermill": {
     "duration": 0.056248,
     "end_time": "2021-04-03T05:00:43.103598",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.047350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_A2C(env_train, model_name, timesteps=25000):\n",
    "    start = time.time()\n",
    "    model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"/kaggle/working/{model_name}\")\n",
    "    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_ACER(env_train, model_name, timesteps=25000):\n",
    "    start = time.time()\n",
    "    model = ACER('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"/kaggle/working/{model_name}\")\n",
    "    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_DDPG(env_train, model_name, timesteps=10000):\n",
    "    # add the noise objects for DDPG\n",
    "    n_actions = env_train.action_space.shape[-1]\n",
    "    param_noise = None\n",
    "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "    start = time.time()\n",
    "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"/kaggle/working/{model_name}\")\n",
    "    print(' - Training time (DDPG): ', (end-start)/60,' minutes')\n",
    "    return model\n",
    "\n",
    "def train_PPO(env_train, model_name, timesteps=50000):\n",
    "    start = time.time()\n",
    "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\n",
    "    \n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"/kaggle/working/{model_name}\")\n",
    "    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_GAIL(env_train, model_name, timesteps=1000):\n",
    "    start = time.time()\n",
    "    # generate expert trajectories\n",
    "    model = SAC('MLpPolicy', env_train, verbose=1)\n",
    "    generate_expert_traj(model, 'expert_model_gail', n_timesteps=100, n_episodes=10)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = ExpertDataset(expert_path='expert_model_gail.npz', traj_limitation=10, verbose=1)\n",
    "    model = GAIL('MLpPolicy', env_train, dataset, verbose=1)\n",
    "\n",
    "    model.learn(total_timesteps=1000)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"/kaggle/working/{model_name}\")\n",
    "    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-camera",
   "metadata": {
    "papermill": {
     "duration": 0.035164,
     "end_time": "2021-04-03T05:00:43.174458",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.139294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"additional\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Additional Functions\n",
    "        <a class=\"anchor-link\" href=\"#additional\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complex-berkeley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.254427Z",
     "iopub.status.busy": "2021-04-03T05:00:43.253753Z",
     "iopub.status.idle": "2021-04-03T05:00:43.257932Z",
     "shell.execute_reply": "2021-04-03T05:00:43.257250Z"
    },
    "papermill": {
     "duration": 0.048232,
     "end_time": "2021-04-03T05:00:43.258157",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.209925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_split(df,start,end):\n",
    "    data = df[(df.datadate >= start) & (df.datadate < end)]\n",
    "    data=data.sort_values(['datadate','tic'],ignore_index=True)\n",
    "    data.index = data.datadate.factorize()[0]\n",
    "    return data\n",
    "\n",
    "def get_validation_sharpe(iteration):\n",
    "    df_total_value = pd.read_csv('/kaggle/working/account_value_validation_{}.csv'.format(iteration), index_col=0)\n",
    "    df_total_value.columns = ['account_value_train']\n",
    "    df_total_value['daily_return'] = df_total_value.pct_change(1)\n",
    "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n",
    "             df_total_value['daily_return'].std()\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-sunrise",
   "metadata": {
    "papermill": {
     "duration": 0.034922,
     "end_time": "2021-04-03T05:00:43.328501",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.293579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"predvalid\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Predict-Validate\n",
    "        <a class=\"anchor-link\" href=\"#predvalid\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stock-robert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.411283Z",
     "iopub.status.busy": "2021-04-03T05:00:43.410568Z",
     "iopub.status.idle": "2021-04-03T05:00:43.414371Z",
     "shell.execute_reply": "2021-04-03T05:00:43.413801Z"
    },
    "papermill": {
     "duration": 0.05106,
     "end_time": "2021-04-03T05:00:43.414516",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.363456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DRL_prediction(df,\n",
    "                   model,\n",
    "                   name,\n",
    "                   last_state,\n",
    "                   iter_num,\n",
    "                   unique_trade_date,\n",
    "                   rebalance_window,\n",
    "                   turbulence_threshold,\n",
    "                   initial):\n",
    "\n",
    "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n",
    "    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\n",
    "                                                   turbulence_threshold=turbulence_threshold,\n",
    "                                                   initial=initial,\n",
    "                                                   previous_state=last_state,\n",
    "                                                   model_name=name,\n",
    "                                                   iteration=iter_num)])\n",
    "    obs_trade = env_trade.reset()\n",
    "\n",
    "    for i in range(len(trade_data.index.unique())):\n",
    "        action, _states = model.predict(obs_trade)\n",
    "        obs_trade, rewards, dones, info = env_trade.step(action)\n",
    "        if i == (len(trade_data.index.unique()) - 2):\n",
    "            last_state = env_trade.render()\n",
    "\n",
    "    df_last_state = pd.DataFrame({'last_state': last_state})\n",
    "    df_last_state.to_csv('/kaggle/working/last_state_{}_{}.csv'.format(name, i), index=False)\n",
    "    return last_state\n",
    "\n",
    "def DRL_validation(model, test_data, test_env, test_obs) -> None:\n",
    "    for i in range(len(test_data.index.unique())):\n",
    "        action, _states = model.predict(test_obs)\n",
    "        test_obs, rewards, dones, info = test_env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-anthropology",
   "metadata": {
    "papermill": {
     "duration": 0.036259,
     "end_time": "2021-04-03T05:00:43.486375",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.450116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"ensemble\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Ensemble\n",
    "        <a class=\"anchor-link\" href=\"#ensemble\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wrapped-pathology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.582758Z",
     "iopub.status.busy": "2021-04-03T05:00:43.581780Z",
     "iopub.status.idle": "2021-04-03T05:00:43.585359Z",
     "shell.execute_reply": "2021-04-03T05:00:43.584799Z"
    },
    "papermill": {
     "duration": 0.063935,
     "end_time": "2021-04-03T05:00:43.585499",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.521564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\n",
    "    last_state_ensemble = []\n",
    "    ppo_sharpe_list = []\n",
    "    ddpg_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "\n",
    "    model_use = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "        print(\" - A2C Training\")\n",
    "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=30000)\n",
    "        print(\" - A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_a2c = get_validation_sharpe(i)\n",
    "        print(\" - A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "        print(\" - PPO Training\")\n",
    "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\n",
    "        print(\" - PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\" - PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "        print(\" - DDPG Training\")\n",
    "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=10000)\n",
    "        print(\" - DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        \n",
    "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ddpg = get_validation_sharpe(i)\n",
    "\n",
    "        ppo_sharpe_list.append(sharpe_ppo)\n",
    "        a2c_sharpe_list.append(sharpe_a2c)\n",
    "        ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "        # Model Selection based on sharpe ratio\n",
    "        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "            model_ensemble = model_ppo\n",
    "            model_use.append('PPO')\n",
    "        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "            model_ensemble = model_a2c\n",
    "            model_use.append('A2C')\n",
    "        else:\n",
    "            model_ensemble = model_ddpg\n",
    "            model_use.append('DDPG')\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
    "                                             last_state=last_state_ensemble, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wired-burlington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.663960Z",
     "iopub.status.busy": "2021-04-03T05:00:43.662743Z",
     "iopub.status.idle": "2021-04-03T07:46:32.346383Z",
     "shell.execute_reply": "2021-04-03T07:46:32.345691Z"
    },
    "papermill": {
     "duration": 9948.72573,
     "end_time": "2021-04-03T07:46:32.346561",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.620831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.832255752881368  minutes\n",
      " - A2C Validation from:  20151002 to  20160104\n",
      " - A2C Sharpe Ratio:  0.09353248648925075\n",
      " - PPO Training\n",
      " - Training time (PPO):  5.9989074269930525  minutes\n",
      " - PPO Validation from:  20151002 to  20160104\n",
      " - PPO Sharpe Ratio:  -0.005994288788104698\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1400449395179748  minutes\n",
      " - DDPG Validation from:  20151002 to  20160104\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1083119.7637464912\n",
      "total_reward:83119.76374649117\n",
      "total_cost:  5494.1027992952395\n",
      "total trades:  1417\n",
      "Sharpe:  0.2576371335580068\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8303528785705567  minutes\n",
      " - A2C Validation from:  20160104 to  20160405\n",
      " - A2C Sharpe Ratio:  0.15809217003606382\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.068517772356669  minutes\n",
      " - PPO Validation from:  20160104 to  20160405\n",
      " - PPO Sharpe Ratio:  0.18452172029511837\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1212442557017008  minutes\n",
      " - DDPG Validation from:  20160104 to  20160405\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1083119.7637464912\n",
      "end_total_asset:1062303.9905378337\n",
      "total_reward:-20815.773208657512\n",
      "total_cost:  6098.402412863999\n",
      "total trades:  1555\n",
      "Sharpe:  -0.06403188830170192\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.839488422870636  minutes\n",
      " - A2C Validation from:  20160405 to  20160705\n",
      " - A2C Sharpe Ratio:  0.06502339263684465\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.048302129904429  minutes\n",
      " - PPO Validation from:  20160405 to  20160705\n",
      " - PPO Sharpe Ratio:  0.05723528943286211\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1290282487869263  minutes\n",
      " - DDPG Validation from:  20160405 to  20160705\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1062303.9905378337\n",
      "end_total_asset:1081791.6163194007\n",
      "total_reward:19487.62578156707\n",
      "total_cost:  1385.7335446946138\n",
      "total trades:  1138\n",
      "Sharpe:  0.09347309036393255\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8059765338897704  minutes\n",
      " - A2C Validation from:  20160705 to  20161003\n",
      " - A2C Sharpe Ratio:  0.07480672492960537\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.146949724356333  minutes\n",
      " - PPO Validation from:  20160705 to  20161003\n",
      " - PPO Sharpe Ratio:  0.03935879304677609\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1346707741419475  minutes\n",
      " - DDPG Validation from:  20160705 to  20161003\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1081791.6163194007\n",
      "end_total_asset:1162078.8271808461\n",
      "total_reward:80287.2108614454\n",
      "total_cost:  3329.6985107904698\n",
      "total trades:  1257\n",
      "Sharpe:  0.3483136994005181\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.793634291489919  minutes\n",
      " - A2C Validation from:  20161003 to  20170103\n",
      " - A2C Sharpe Ratio:  0.45087006236220634\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.056151592731476  minutes\n",
      " - PPO Validation from:  20161003 to  20170103\n",
      " - PPO Sharpe Ratio:  0.628849677985059\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1135732849438986  minutes\n",
      " - DDPG Validation from:  20161003 to  20170103\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1162078.8271808461\n",
      "end_total_asset:1173149.1158356532\n",
      "total_reward:11070.288654807024\n",
      "total_cost:  4521.949485720843\n",
      "total trades:  1391\n",
      "Sharpe:  0.06578779841930214\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.891555166244507  minutes\n",
      " - A2C Validation from:  20170103 to  20170404\n",
      " - A2C Sharpe Ratio:  0.2802628947979222\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.149382638931274  minutes\n",
      " - PPO Validation from:  20170103 to  20170404\n",
      " - PPO Sharpe Ratio:  0.31084307835659236\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1374158978462219  minutes\n",
      " - DDPG Validation from:  20170103 to  20170404\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1173149.1158356532\n",
      "end_total_asset:1202747.8183996272\n",
      "total_reward:29598.702563974075\n",
      "total_cost:  6129.222844653255\n",
      "total trades:  1270\n",
      "Sharpe:  0.200504654918944\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8245046814282735  minutes\n",
      " - A2C Validation from:  20170404 to  20170705\n",
      " - A2C Sharpe Ratio:  0.1303850342276641\n",
      " - PPO Training\n",
      " - Training time (PPO):  5.993836836020152  minutes\n",
      " - PPO Validation from:  20170404 to  20170705\n",
      " - PPO Sharpe Ratio:  0.18275713012893358\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1339492003122966  minutes\n",
      " - DDPG Validation from:  20170404 to  20170705\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1202747.8183996272\n",
      "end_total_asset:1234756.422711568\n",
      "total_reward:32008.604311940726\n",
      "total_cost:  2818.7430762744993\n",
      "total trades:  906\n",
      "Sharpe:  0.20487173395840685\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8328093727429708  minutes\n",
      " - A2C Validation from:  20170705 to  20171003\n",
      " - A2C Sharpe Ratio:  0.3364998656845228\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.014858059088389  minutes\n",
      " - PPO Validation from:  20170705 to  20171003\n",
      " - PPO Sharpe Ratio:  0.21848722998325407\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.130077882607778  minutes\n",
      " - DDPG Validation from:  20170705 to  20171003\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1234756.422711568\n",
      "end_total_asset:1357448.4241315438\n",
      "total_reward:122692.00141997589\n",
      "total_cost:  7992.0927253602395\n",
      "total trades:  1527\n",
      "Sharpe:  0.6707896202195769\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.7956970492998758  minutes\n",
      " - A2C Validation from:  20171003 to  20180103\n",
      " - A2C Sharpe Ratio:  0.4703198572508627\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.050198006629944  minutes\n",
      " - PPO Validation from:  20171003 to  20180103\n",
      " - PPO Sharpe Ratio:  0.38228103816955683\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1192640264829  minutes\n",
      " - DDPG Validation from:  20171003 to  20180103\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1357448.4241315438\n",
      "end_total_asset:1378509.683874568\n",
      "total_reward:21061.25974302413\n",
      "total_cost:  1969.611436279544\n",
      "total trades:  244\n",
      "Sharpe:  0.08670589813036501\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8523768107096354  minutes\n",
      " - A2C Validation from:  20180103 to  20180405\n",
      " - A2C Sharpe Ratio:  -0.009720655486279997\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.0587639530499775  minutes\n",
      " - PPO Validation from:  20180103 to  20180405\n",
      " - PPO Sharpe Ratio:  0.023304990460200598\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1209626873334249  minutes\n",
      " - DDPG Validation from:  20180103 to  20180405\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1378509.683874568\n",
      "end_total_asset:1378566.8882111702\n",
      "total_reward:57.2043366022408\n",
      "total_cost:  7453.912258773169\n",
      "total trades:  1113\n",
      "Sharpe:  0.005654973100331562\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8261479338010151  minutes\n",
      " - A2C Validation from:  20180405 to  20180705\n",
      " - A2C Sharpe Ratio:  -0.1395440715869885\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.300014007091522  minutes\n",
      " - PPO Validation from:  20180405 to  20180705\n",
      " - PPO Sharpe Ratio:  -0.1332871975475709\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1648189107577005  minutes\n",
      " - DDPG Validation from:  20180405 to  20180705\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1378566.8882111702\n",
      "end_total_asset:1417481.6485164408\n",
      "total_reward:38914.76030527055\n",
      "total_cost:  5139.98241700308\n",
      "total trades:  706\n",
      "Sharpe:  0.3064614558578452\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8964206059773763  minutes\n",
      " - A2C Validation from:  20180705 to  20181003\n",
      " - A2C Sharpe Ratio:  0.1482251711225829\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.371890632311503  minutes\n",
      " - PPO Validation from:  20180705 to  20181003\n",
      " - PPO Sharpe Ratio:  0.13816924058976657\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1477120955785116  minutes\n",
      " - DDPG Validation from:  20180705 to  20181003\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1417481.6485164408\n",
      "end_total_asset:1420043.3559244915\n",
      "total_reward:2561.7074080507737\n",
      "total_cost:  856.3710687996346\n",
      "total trades:  165\n",
      "Sharpe:  0.05518779236867416\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8507928252220154  minutes\n",
      " - A2C Validation from:  20181003 to  20190104\n",
      " - A2C Sharpe Ratio:  -0.4111601655923039\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.189200448989868  minutes\n",
      " - PPO Validation from:  20181003 to  20190104\n",
      " - PPO Sharpe Ratio:  -0.42265967050516173\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1638171513875326  minutes\n",
      " - DDPG Validation from:  20181003 to  20190104\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1420043.3559244915\n",
      "end_total_asset:1543121.5287531668\n",
      "total_reward:123078.17282867525\n",
      "total_cost:  2179.5342090788013\n",
      "total trades:  1077\n",
      "Sharpe:  0.3568931493553343\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8840416550636292  minutes\n",
      " - A2C Validation from:  20190104 to  20190405\n",
      " - A2C Sharpe Ratio:  -0.11252237480268844\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.148187593619029  minutes\n",
      " - PPO Validation from:  20190104 to  20190405\n",
      " - PPO Sharpe Ratio:  0.060021810795679774\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.133009703954061  minutes\n",
      " - DDPG Validation from:  20190104 to  20190405\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1543121.5287531668\n",
      "end_total_asset:1555128.8533785248\n",
      "total_reward:12007.324625357985\n",
      "total_cost:  1327.7519451937872\n",
      "total trades:  128\n",
      "Sharpe:  0.2594637592737058\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.869217542807261  minutes\n",
      " - A2C Validation from:  20190405 to  20190708\n",
      " - A2C Sharpe Ratio:  0.18416096917338912\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.323496067523957  minutes\n",
      " - PPO Validation from:  20190405 to  20190708\n",
      " - PPO Sharpe Ratio:  0.2708457614851077\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.174839695294698  minutes\n",
      " - DDPG Validation from:  20190405 to  20190708\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1555128.8533785248\n",
      "end_total_asset:1556408.580368754\n",
      "total_reward:1279.7269902292173\n",
      "total_cost:  1966.2744670042223\n",
      "total trades:  335\n",
      "Sharpe:  0.035241713417916785\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.835954757531484  minutes\n",
      " - A2C Validation from:  20190708 to  20191004\n",
      " - A2C Sharpe Ratio:  -0.1582461001898224\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.39305872519811  minutes\n",
      " - PPO Validation from:  20190708 to  20191004\n",
      " - PPO Sharpe Ratio:  -0.22333278504615614\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1430515925089517  minutes\n",
      " - DDPG Validation from:  20190708 to  20191004\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1556408.580368754\n",
      "end_total_asset:1556284.9574554358\n",
      "total_reward:-123.62291331822053\n",
      "total_cost:  416.8812960580445\n",
      "total trades:  60\n",
      "Sharpe:  -0.014322628786961633\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.8801740487416585  minutes\n",
      " - A2C Validation from:  20191004 to  20200106\n",
      " - A2C Sharpe Ratio:  -0.060374537450217466\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.548184875647227  minutes\n",
      " - PPO Validation from:  20191004 to  20200106\n",
      " - PPO Sharpe Ratio:  -0.28642335861146245\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.1884012619654338  minutes\n",
      " - DDPG Validation from:  20191004 to  20200106\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1556284.9574554358\n",
      "end_total_asset:1541412.452256473\n",
      "total_reward:-14872.505198962754\n",
      "total_cost:  905.785864722898\n",
      "total trades:  174\n",
      "Sharpe:  -0.42402708879226847\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.9435046076774598  minutes\n",
      " - A2C Validation from:  20200106 to  20200406\n",
      " - A2C Sharpe Ratio:  -0.42164233702789156\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.6232333739598594  minutes\n",
      " - PPO Validation from:  20200106 to  20200406\n",
      " - PPO Sharpe Ratio:  -0.40765467006353256\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.2478465676307677  minutes\n",
      " - DDPG Validation from:  20200106 to  20200406\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1541412.452256473\n",
      "end_total_asset:1544521.953681219\n",
      "total_reward:3109.5014247458894\n",
      "total_cost:  374.71457843097204\n",
      "total trades:  96\n",
      "Sharpe:  0.35149152146226226\n",
      "Ensemble Strategy took:  165.81005473534267  minutes\n"
     ]
    }
   ],
   "source": [
    "    run_ensemble_strategy(df=df, \n",
    "                          unique_trade_date= unique_trade_date,\n",
    "                          rebalance_window = rebalance_window,\n",
    "                          validation_window=validation_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-sense",
   "metadata": {
    "papermill": {
     "duration": 0.074992,
     "end_time": "2021-04-03T07:46:32.497986",
     "exception": false,
     "start_time": "2021-04-03T07:46:32.422994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"references\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>References\n",
    "        <a class=\"anchor-link\" href=\"#references\" target=\"_self\">Â¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-puzzle",
   "metadata": {
    "papermill": {
     "duration": 0.074825,
     "end_time": "2021-04-03T07:46:32.648223",
     "exception": false,
     "start_time": "2021-04-03T07:46:32.573398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy.<br>\n",
    "In ICAIF â20: ACM International Conference on AI in Finance, Oct. 15â16, 2020, Manhattan, NY. ACM, New York, NY, USA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10126.704499,
   "end_time": "2021-04-03T07:46:34.243540",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-03T04:57:47.539041",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
