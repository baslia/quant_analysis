{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This guide is based on notes from this TensorFlow 2.0 course and is organized as follows\n",
    "\n",
    "- Building a Deep Q-Learning Trading Network\n",
    "- Stock Market Data Preprocessing\n",
    "- Training our Deep Q-Learning Trading Agent\n",
    "- Summary: Deep Reinforcement Learning for Trading with TensorFlow 2.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbd414f7fcf0df42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Building a Deep Q-Learning Trading Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1033c151de7f008b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "import yfinance as yf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.266814Z",
     "start_time": "2024-02-24T16:53:16.100946Z"
    }
   },
   "id": "806a576fa484e949",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining our Deep Q-Learning Trader\n",
    "\n",
    "Now we need to define the algorithm itself with the AI_Trader class, below are a few important points:\n",
    "\n",
    "- In trading we have an action space of 3: Buy, Sell, and Sit\n",
    "- We set the experience replay memory to `deque` with 2000 elements inside it\n",
    "- We create an empty list with `inventory` which contains the stocks we've already bought\n",
    "- We need to set a `gamma` parameter to `0.95`, which helps to maximize the current reward over the long-term\n",
    "- The epsilon parameter is used to determine whether we should use a random action or to use the model for the action. We start by setting it to 1.0 so that it takes random actions in the beginning when the model is not trained.\n",
    "- Over time we want to decrease the random actions and instead we can mostly use the trained model, so we set epsilon_final to 0.01\n",
    "- We're then set the speed of decreasing epsilon in the `epsilon_decay` parameter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d94a49df831fa474"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "  \n",
    "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
    "    \n",
    "    self.state_size = state_size\n",
    "    self.action_space = action_space\n",
    "    self.memory = deque(maxlen=2000)\n",
    "    self.inventory = []\n",
    "    self.model_name = model_name\n",
    "    \n",
    "    self.gammsa = 0.95\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_final = 0.01\n",
    "    self.epsilon_decay = 0.995"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.271459Z",
     "start_time": "2024-02-24T16:53:21.267325Z"
    }
   },
   "id": "37690641019fb9f1",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Neural Network\n",
    "\n",
    "Next we need to start defining our neural network.\n",
    "\n",
    "The first step to define our neural network is to define a function called `model_builder` which doesn't take any arguments, just the keyword `self`.\n",
    "\n",
    "We then define the model with `tf.keras.models.Sequential()`.\n",
    "\n",
    "To define with model's states, which are the previous `n` days and stock prices of the days.\n",
    "\n",
    "A state is just a vector of numbers and we can use a fully connected network, or a dense network.\n",
    "\n",
    "Next, we add the first dense layer with `tf.keras.layers.Dense()` and specify the number of neurons in the layer to 32 and set the activation to `relu`. We also need to define the input shape in the first layer with `input_dim=self.state_size`\n",
    "\n",
    "We're going to use 3 hidden layers in this network, so we add 2 more and change the architecture of to 64 neurons in the second and 128 for the last layer.\n",
    "\n",
    "We then need to define the output layer and compile the network.\n",
    "\n",
    "To define the output layer we need to set the number of neurons to the number of actions we can take, 3 in this case. We're also going to change the activation function to `relu` because we're using mean-squared error for the loss:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cec95351c2c2a37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def model_builder(self):\n",
    "      \n",
    "      model = Sequential()\n",
    "      \n",
    "      model.add(Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "      model.add(Dense(units=64, activation='relu'))\n",
    "      model.add(Dense(units=128, activation='relu'))\n",
    "      model.add(Dense(units=self.action_space, activation='linear'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.275291Z",
     "start_time": "2024-02-24T16:53:21.270769Z"
    }
   },
   "id": "14ca0d0d8ab08d30",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we need to compile the model. Since this is a regression task we can't use accuracy as our loss, so we use `mse`. We then use the `Adam` optimizer and set the learning rate to 0.001 and return the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16eb2c6f63920f13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model.compile(loss='mse', optimizer=tf.keras.optimizer.Adam(lr=0.001))\n",
    "# return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.276568Z",
     "start_time": "2024-02-24T16:53:21.274247Z"
    }
   },
   "id": "67edd37973a4791f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a Trading Function\n",
    "\n",
    "Now that we've defined the neural network, we need to build a function to trade that takes the state as input and returns an action to perform in that state.\n",
    "\n",
    "To do this we're going to create a function called `trade` that takes in one argument: `state`.\n",
    "\n",
    "For each state, we need to determine if we should use a randomly generated action or the neural network.\n",
    "\n",
    "To do this, we use the `random` library, and if it is less than our `epsilon` we return a random action with `random.randrange()` and pass in `self.action_space`.\n",
    "\n",
    "If the number is greater than `epsilon` we use our model to choose the action. To do this, we define actions equal to `self.model.predict` and pass in the state as the argument.\n",
    "\n",
    "We then return a single number with np.argmax to return only the action with the highest probability.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "- The function takes as input the shape and generates a random number\n",
    "- If the number is less than or equal to epsilon it will generate a random action (this will always be the case in the beginning)\n",
    "- If it is greater than epsilon it will use the model to perform a prediction on the input state and return the action that has the highest probability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2b4cc1affddc76a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def trade(self, state):\n",
    "      if random.random() <= self.epsilon:\n",
    "          return random.randrange(self.action_space)\n",
    "      \n",
    "      actions = self.model.predict(actions[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.280096Z",
     "start_time": "2024-02-24T16:53:21.277221Z"
    }
   },
   "id": "54da10b16a3ce1fb",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model\n",
    "\n",
    "Now that we've implemented the `trade` function let's build a custom training function.\n",
    "\n",
    "This function will take a batch of saved data and train the model on that, below is a step-by-step process to do this:\n",
    "\n",
    "- We define this function `batch_trade` and it will take `batch_size` as an argument\n",
    "- We select data from the experience replay memory by first setting `batch` to an empty list\n",
    "- We then iterate through the memory with a for loop\n",
    "- Since we're dealing with time series data we need to sample from the end of the memory instead of randomly sampling from it\n",
    "- Now that we have a batch of data we need to iterate through each batch—`state`, `reward`, `next_state`, and `done`—and train the model with this\n",
    "- If the agent is not in a terminal state we calculate the discounted total reward as the current `reward`\n",
    "- Next we define the `target` variable which is also predicted by the model\n",
    "- Next we fit the model with `self.model.fit()`\n",
    "- At the end of this function we want to decrease the epsilon parameter so that we slowly stop performing random actions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1494ee94b0eb5f5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def batch_train(self, batch_size):\n",
    "\n",
    "    batch = []\n",
    "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "      batch.append(self.memory[i])\n",
    "\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "      reward = reward\n",
    "      if not done:\n",
    "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "\n",
    "      target = self.model.predict(state)\n",
    "      target[0][action] = reward\n",
    "\n",
    "      self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "    if self.epsilon > self.epsilon_final:\n",
    "      self.epsilon *= self.epsilon_decay"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.283792Z",
     "start_time": "2024-02-24T16:53:21.281196Z"
    }
   },
   "id": "1ef9e3a50de590ef",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Stock Market Data Preprocessing\n",
    "\n",
    "Now that we've built our `AI_Trader` class we now need to create a few helper functions that will be used in the learning process.\n",
    "\n",
    "In particular, we need to define the following 3 functions:\n",
    "\n",
    "1. sigmoid - sigmoid is an activation function, generally used at the end of a network for binary classification as it scales a number to a range from 0 to 1. This will be used to normalize stock price data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6a624fcbf419c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.287579Z",
     "start_time": "2024-02-24T16:53:21.283767Z"
    }
   },
   "id": "4f064699059bead",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. stocks_price_format - this is a formatting function to print out the prices of the stocks we bought or sold."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3de77cfe5ff6d71f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def stocks_price_format(n):\n",
    "  if n < 0:\n",
    "    return \"- $ {0:2f}\".format(abs(n))\n",
    "  else:\n",
    "    return \"$ {0:2f}\".format(abs(n))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.305161Z",
     "start_time": "2024-02-24T16:53:21.287045Z"
    }
   },
   "id": "200ed199ea90bf4c",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. dataset_loader - this function connects with a data source and pulls the stock data from it, in this case we're loading data from Yahoo Finance:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64442e08f1b3e91e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def dataset_loader(stock_name):\n",
    "  # dataset = data_reader.DataReader(stock_name, start=\"2010-01-01\", end=\"2020-01-01\", data_source=\"yahoo\")\n",
    "  # dataset = data_reader.DataReader(stock_name, data_source=\"yahoo\")\n",
    "  # start_date = str(dataset.index[0]).split()[0]\n",
    "  # end_date = str(dataset.index[-1]).split()[0]\n",
    "  dataset = yf.download(stock_name)\n",
    "  close = dataset['Close']\n",
    "  return close"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:21.305616Z",
     "start_time": "2024-02-24T16:53:21.290393Z"
    }
   },
   "id": "5106ddc678c8b50b",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we can take a look at the AAPL dataset. With this information we are going to build states for our network."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca928ccaaeef2426"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/yfinance/utils.py:788: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    },
    {
     "data": {
      "text/plain": "Date\n1980-12-12    0.128348\n1980-12-15    0.121652\n1980-12-16    0.112723\n1980-12-17    0.115513\n1980-12-18    0.118862\nName: Close, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.257708Z",
     "start_time": "2024-02-24T16:53:21.294693Z"
    }
   },
   "id": "b09a596824034f60",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## State Creator\n",
    "\n",
    "Now that we have our dataset_loader function we need to create a function that takes this data and generates states from it.\n",
    "\n",
    "Let's first look at how we can translate the problem of stock market trading to a reinforcement learning environment.\n",
    "\n",
    "- Each point on a stock graph is just a floating number that represents a stock price at a given time.\n",
    "- Our task is to predict what is going to happen in the next period, and as mentioned there are 3 possible actions: buy, sell, or sit.\n",
    "This is regression problem - let's say we have a `window_size = 5` so we use 5 states to predict our target, which is a continuous number.\n",
    "\n",
    "Instead of predicting real numbers for our target we instead want to predict one of our 3 actions.\n",
    "\n",
    "Next we're going change our input states to be differences in stock prices, which will represent price changes over time.\n",
    "\n",
    "To implement this in Python we're going to create a function `state_creator` which takes 3 arguments: `data`, `timestep`, and `window_size`:\n",
    "\n",
    "- We first need to calculate the starting_id\n",
    "- When the starting_id is positive we create a state and if it is negative we append the info until we get to the window_size\n",
    "- Next we define an empty list called state and iterate through the window_data list.\n",
    "- As we append the state we need to normalize the price data with the sigmoid function\n",
    "- To complete the function we return a NumPy array of the state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ef92470a2104d6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def state_creator(data, timestep, window_size):\n",
    "  starting_id = timestep - window_size + 1\n",
    "  \n",
    "  if starting_id >= 0:\n",
    "    window_data = data[starting_id:timestep+1]\n",
    "  else:\n",
    "    window_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
    "  \n",
    "  state = []\n",
    "  for i in range(window_size - 1):\n",
    "    state.append(sigmoid(window_data[i+1] - window_data[i]))\n",
    "  \n",
    "  return np.array([state])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.261803Z",
     "start_time": "2024-02-24T16:53:22.257868Z"
    }
   },
   "id": "39fd453633768827",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading a Dataset\n",
    "\n",
    "Now that we have our `state_creator` function we can load our dataset.\n",
    "\n",
    "First we need to define a new variable called `stock_name`, and for this example we'll use `AAPL`.\n",
    "\n",
    "Then we define a variable called `data` with our `dataset_loader` function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94690b2bbb65c4b2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/yfinance/utils.py:788: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    },
    {
     "data": {
      "text/plain": "Date\n1980-12-12    0.128348\n1980-12-15    0.121652\n1980-12-16    0.112723\n1980-12-17    0.115513\n1980-12-18    0.118862\nName: Close, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.640398Z",
     "start_time": "2024-02-24T16:53:22.261210Z"
    }
   },
   "id": "c245e79975bcb556",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Training the Q-Learning Trading Agent\n",
    "\n",
    "Before we proceed to training our model, let's define a few hyperparameters, including:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b40d53c6616453"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 1000\n",
    "\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.640944Z",
     "start_time": "2024-02-24T16:53:22.638295Z"
    }
   },
   "id": "c2669a1ef7b46129",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to define our trading agent, and let's take a look at a summary of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60fc5bdf862495d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "    def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
    "      self.state_size = state_size\n",
    "      self.action_space = action_space\n",
    "      self.memory = deque(maxlen=2000)\n",
    "      self.inventory = []\n",
    "      self.model_name = model_name\n",
    "      \n",
    "      self.gamma = 0.95\n",
    "      self.epsilon = 1.0\n",
    "      self.epsilon_final = 0.01\n",
    "      self.epsilon_decay = 0.995\n",
    "        \n",
    "    def model_builder(self):\n",
    "        model = Sequential()\n",
    "      \n",
    "        model.add(Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "        model.add(Dense(units=64, activation='relu'))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(units=self.action_space, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "        \n",
    "        return model\n",
    "  \n",
    "    def trade(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "      \n",
    "        actions = self.model.predict(actions[0])\n",
    "        return np.argmax(actions[0])\n",
    "    \n",
    "    def batch_train(self, batch_size):\n",
    "        batch = []\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "            batch.append(self.memory[i])\n",
    "            \n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            reward = reward\n",
    "            if not done:\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "            \n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_final:\n",
    "            self.epsilon *= self.epsilon_decay"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.647682Z",
     "start_time": "2024-02-24T16:53:22.644242Z"
    }
   },
   "id": "58c23c8e7d02a1a8",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to define our trading agent, and let's take a look at a summary of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2beb2c26d3c77d1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11171 (43.64 KB)\n",
      "Trainable params: 11171 (43.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(window_size)\n",
    "model = trader.model_builder()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:53:22.710172Z",
     "start_time": "2024-02-24T16:53:22.647690Z"
    }
   },
   "id": "a8a9684fd1e5589a",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining a Training Loop\n",
    "\n",
    "Now we need to train our model, which we're going to do with a `for` loop that will iterate through all of the `episodes`.\n",
    "\n",
    "- Next we want to print out the current episode\n",
    "- We then need to define our initial state with `state_creator`\n",
    "- Then we define 2 variables so that we can keep track of `total_profit` and we set our inventory to 0 at the beginning of an episode with `trader.inventory = []`\n",
    "- Next we define our timestep (1 timestep is 1 day) with a for loop, which represents how many samples we have. To do this we need to define our `action`, `next_state`, and `reward`.\n",
    "- Then we want to update our `inventory` based on the given `action`\n",
    "- Based on the actions we can calculate our `reward` and update the `total_profit`\n",
    "- We then need to check if this is the last sample in our dataset\n",
    "- Next we need to append all of the data to our trader's experience replay buffer with `trader.memory.append()`\n",
    "- We then change the state to the `next_state` so we can iterate through the whole `episode`\n",
    "- Finally, we want to print out the `total_profit` if `done = True` and add print statements to when we buy or sell and how what the profit is\n",
    "There are two more things to do before starting the training process:\n",
    "\n",
    "- We need to check if we have more information in our `memory` than our `batch_size`. If that is true we call `trader.batch_train` and pass in the `batch_size` argument\n",
    "- We're then going to check if the number of episodes is divisible by 10, and if that is the case we're going to save the model with `trader.model.save()` in an H5 file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca0d503581304a4a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/2141800173.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  window_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10889 [00:00<?, ?it/s]/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/640152755.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  trader.inventory.append(data[t])\n",
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/640152755.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/640152755.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  reward = max(data[t] - buy_price, 0)\n",
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/640152755.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  total_profit += data[t] - buy_price\n",
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/640152755.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
      "/var/folders/_n/nybmwjg90rxfzcynss3bqkr80000gp/T/ipykernel_52505/2141800173.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  state.append(sigmoid(window_data[i+1] - window_data[i]))\n",
      "  0%|          | 32/10889 [00:00<00:01, 7329.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Trader bought:  $ 0.137835\n",
      "AI Trader sold:  $ 0.145089  Profit: $ 0.007254\n",
      "AI Trader bought:  $ 0.160714\n",
      "AI Trader sold:  $ 0.152344  Profit: - $ 0.008370\n",
      "AI Trader bought:  $ 0.154018\n",
      "AI Trader bought:  $ 0.150670\n",
      "AI Trader sold:  $ 0.137835  Profit: - $ 0.016183\n",
      "AI Trader sold:  $ 0.141183  Profit: - $ 0.009487\n",
      "AI Trader bought:  $ 0.136161\n",
      "AI Trader sold:  $ 0.136719  Profit: $ 0.000558\n",
      "AI Trader bought:  $ 0.145089\n",
      "AI Trader bought:  $ 0.146763\n",
      "AI Trader bought:  $ 0.142857\n",
      "AI Trader bought:  $ 0.138393\n",
      "AI Trader sold:  $ 0.133371  Profit: - $ 0.011718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AI_Trader' object has no attribute 'gamma'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 43\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m########################\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     42\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(trader\u001B[38;5;241m.\u001B[39mmemory) \u001B[38;5;241m>\u001B[39m batch_size:\n\u001B[0;32m---> 43\u001B[0m     \u001B[43mtrader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m episode \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     46\u001B[0m   trader\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mai_trader_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(episode))\n",
      "Cell \u001B[0;32mIn[14], line 40\u001B[0m, in \u001B[0;36mAI_Trader.batch_train\u001B[0;34m(self, batch_size)\u001B[0m\n\u001B[1;32m     38\u001B[0m reward \u001B[38;5;241m=\u001B[39m reward\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[0;32m---> 40\u001B[0m     reward \u001B[38;5;241m=\u001B[39m reward \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgamma\u001B[49m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mamax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(next_state)[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     41\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(state)\n\u001B[1;32m     42\u001B[0m target[\u001B[38;5;241m0\u001B[39m][action] \u001B[38;5;241m=\u001B[39m reward\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'AI_Trader' object has no attribute 'gamma'"
     ]
    }
   ],
   "source": [
    "for episode in range(1, episodes + 1):\n",
    "  \n",
    "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "  \n",
    "  state = state_creator(data, 0, window_size + 1)\n",
    "  \n",
    "  total_profit = 0\n",
    "  trader.inventory = []\n",
    "  \n",
    "  for t in tqdm(range(data_samples)):\n",
    "    \n",
    "    action = trader.trade(state)\n",
    "    \n",
    "    next_state = state_creator(data, t+1, window_size + 1)\n",
    "    reward = 0\n",
    "    \n",
    "    if action == 1: #Buying\n",
    "      trader.inventory.append(data[t])\n",
    "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "      \n",
    "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
    "      buy_price = trader.inventory.pop(0)\n",
    "      \n",
    "      reward = max(data[t] - buy_price, 0)\n",
    "      total_profit += data[t] - buy_price\n",
    "      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
    "      \n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "      \n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "      print(\"########################\")\n",
    "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "      print(\"########################\")\n",
    "    \n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "      \n",
    "  if episode % 10 == 0:\n",
    "    trader.model.save(\"ai_trader_{}.h5\".format(episode))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:58:55.166633Z",
     "start_time": "2024-02-24T16:58:54.845122Z"
    }
   },
   "id": "926099ef6452aa05",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a32056cd157891e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
