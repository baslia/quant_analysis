{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Different ways pandas really losing to Polars for quick market data analysis\n",
    "\n",
    "Polars is a DataFrame library designed for speed and efficiency.\n",
    "\n",
    "It’s written in Rust and uses parallel execution to process data across multiple CPU cores. This makes it faster than many other DataFrame libraries, including pandas, making it a good choice for tasks that involve large amounts of data.\n",
    "\n",
    "Despite being written in Rust, Polars provides a Python API that is easy to use and familiar to those who have experience with Python.\n",
    "\n",
    "This makes it accessible to a wide range of users, including data scientists and researchers.\n",
    "\n",
    "The choice between the two will depend on the size of your data and how crucial performance is for your work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56080ac3691fff79"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[33mForecasting Toolkit is disabled. To use the Forecasting features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/\u001B[0m\n\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Forecasting Toolkit is disabled. To use the Forecasting features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/</span>\n\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[33mPortfolio Optimization Toolkit is disabled. To use the Optimization features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/\u001B[0m\n\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Portfolio Optimization Toolkit is disabled. To use the Optimization features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/</span>\n\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "The chosen index BRK.B, returns no data. Please check if there is any data available.\n\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The chosen index BRK.B, returns no data. Please check if there is any data available.\n\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "The chosen index BF.B, returns no data. Please check if there is any data available.\n\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The chosen index BF.B, returns no data. Please check if there is any data available.\n\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports and set up\n",
    "\n",
    "# Make sure you run the code in a Jupyter Notebook so you can use the %timeit magic. Then, start by importing pandas, Polars, and OpenBB.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from openbb_terminal.sdk import openbb\n",
    "# We’ll run our tests with 30 years of price data for the 500 stocks currently in the S&P 500. The resulting DataFrame is 32.5MB which is not huge but big enough for testing.\n",
    "\n",
    "url = \"http://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "table = pd.read_html(url)[0]\n",
    "tickers = table.Symbol.tolist()\n",
    "\n",
    "df_pandas = openbb.economy.index(tickers, start_date=\"1990-01-01\")\n",
    "# As you might expect, you can convert a pandas DataFrame to a Polars DataFrame.\n",
    "\n",
    "df_polars = pl.from_pandas(df_pandas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T13:57:32.988399Z",
     "start_time": "2023-08-02T13:53:02.385794Z"
    }
   },
   "id": "bc8e3463bae75ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reading data from CSV\n",
    "\n",
    "# Reading data from CSVs is common. Here’s how to do it.\n",
    "\n",
    "# pandas \n",
    "%timeit pd.read_csv(\"data.csv\")\n",
    "# 458 ms ± 3.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# polars\n",
    "%timeit pl.scan_csv(\"data.csv\")\n",
    "# 3.57 ms ± 4.01 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# If you’ve never seen the output of %timeit before, the first number is the average time it takes to run the operation. In this case pandas took 458 ms per loop and Polars took 3.57 ms per loop.\n",
    "\n",
    "# Polars is 99% faster at reading data from a CSV than pandas."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd9c390b7d821cae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecting data\n",
    "\n",
    "# Selecting data from columns is also common.\n",
    "\n",
    "selected = tickers[:100]\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas[selected]\n",
    "# 673 µs ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.select(pl.col(selected))\n",
    "# 399 µs ± 1.37 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
    "# Notice the difference in syntax. Polars requires the list of columns to selected be wrapped in the pl.col method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb26bce12db4e2bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "\n",
    "# How about filtering data.\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas[df_pandas[\"GE\"] > 100]\n",
    "# 2.55 ms ± 28.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.filter(pl.col(\"GE\") > 100)\n",
    "# 1.27 ms ± 371 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
    "# Polars takes about half the time for simple filter operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e1e02474d5bc99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grouping data\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas.groupby(\"GE\").mean()\n",
    "# 113 ms ± 4.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.groupby(\"GE\").mean()\n",
    "# 16.5 ms ± 3.68 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# pandas groups and aggregates in 113 ms while Polars does it in 16.5 ms."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce85b7e00f466c04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adding new columns\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas.assign(GE_Return=df_pandas[\"GE\"].pct_change())\n",
    "# 3.67 ms ± 23.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.with_columns((pl.col(\"GE\").pct_change()).alias(\"GE_return\"))\n",
    "# 89 µs ± 3.57 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
    "# Polars is 98% faster when adding a new column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a31102bfe9072ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imputing missing data\n",
    "\n",
    "# Pandas\n",
    "%timeit df_pandas[\"GE\"].fillna(0)\n",
    "# 33.2 µs ± 112 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
    "\n",
    "# Polars\n",
    "%timeit df_polars.with_columns(pl.col(\"GE\").fill_null(0))\n",
    "# 81.5 µs ± 169 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
    "# Polars is slower than pandas when filling nulls and nans by about 3x."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae400035c732d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sorting data\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas.sort_values(\"GE\")\n",
    "# 6.45 ms ± 48.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.sort(\"GE\")\n",
    "# 4.54 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# pandas and Polars are pretty close in sorting, but Polars is still faster."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bb0293fa8a4d908"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating rolling statistics\n",
    "\n",
    "# pandas\n",
    "%timeit df_pandas.GE.rolling(window=20).mean()\n",
    "# 184 µs ± 274 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
    "\n",
    "# polars\n",
    "%timeit df_polars.with_columns(pl.col(\"GE\").rolling_mean(20))\n",
    "# 103 µs ± 323 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c47ed99f24f5b11b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Polars beats pandas in a simple 20-day rolling mean calculation.\n",
    "\n",
    "This demonstration only scratches the surface of Polars. It’s also important to note the syntax is different from pandas so there is a learning curve to use it. And as always, it’s important to use the tool that does the job for you. If you’re dealing with massive data sets of tens or hundreds of GBs, then Polars is a good option. If not, then pandas will work fine."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864fb90151bc75eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5e05c5668e57bdfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
