{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear increasing price"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f591813faf28c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-19T17:45:04.195457Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "np.random.seed(11)  # for reproducibility\n",
    "np.set_printoptions(precision=5, suppress=True, linewidth=150)\n",
    "\n",
    "import pandas as pd\n",
    "import backtest as twp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Load data\n",
    "def load_data(type_evol='linear'):\n",
    "    if type_evol == 'linear':\n",
    "        price = np.arange(200/10.0) #linearly increasing prices\n",
    "    elif type_evol == 'sin':\n",
    "        price = np.sin(np.arange(200)/30.0) #sine prices \n",
    "    elif type_evol == 'cos':\n",
    "        price = np.cos(np.arange(200)/30.0)\n",
    "    elif type_evol == 'random_walk':\n",
    "        price = [100]\n",
    "        for i in range(1, 200):\n",
    "            price.append(price[i-1]* np.exp(0.1* np.random.normal(0,1)))\n",
    "    return price"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d093a77f8a6c1ebf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.normal(0,1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f50de40afac1587d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plot data\n",
    "plt.plot(load_data(type_evol='random_walk'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d5c33d97ab136b39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Initialize first state, all items are placed deterministically\n",
    "def init_state(data):\n",
    "    \n",
    "    close = data\n",
    "    diff = np.diff(data)\n",
    "    diff = np.insert(diff, 0, 0)\n",
    "    \n",
    "    #--- Preprocess data\n",
    "    xdata = np.column_stack((close, diff))\n",
    "    xdata = np.nan_to_num(xdata)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    xdata = scaler.fit_transform(xdata)\n",
    "    \n",
    "    state = xdata[0:1, :]\n",
    "    return state, xdata"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9e72806613da1bea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Take Action\n",
    "def take_action(state, xdata, action, signal, time_step):\n",
    "    #this should generate a list of trade signals that at evaluation time are fed to the backtester\n",
    "    #the backtester should get a list of trade signals and a list of price data for the assett\n",
    "    \n",
    "    #make necessary adjustments to state and then return it\n",
    "    time_step += 1\n",
    "    \n",
    "    #if the current iteration is the last state (\"terminal state\") then set terminal_state to 1\n",
    "    if time_step == xdata.shape[0]:\n",
    "        state = xdata[time_step-1:time_step, :]\n",
    "        terminal_state = 1\n",
    "        signal.loc[time_step] = 0\n",
    "        return state, time_step, signal, terminal_state\n",
    "\n",
    "    #move the market data window one step forward\n",
    "    state = xdata[time_step-1:time_step, :]\n",
    "    #take action\n",
    "    if action != 0:\n",
    "        if action == 1:\n",
    "            signal.loc[time_step] = 100\n",
    "        elif action == 2:\n",
    "            signal.loc[time_step] = -100\n",
    "        elif action == 3:\n",
    "            signal.loc[time_step] = 0\n",
    "    terminal_state = 0\n",
    "\n",
    "    return state, time_step, signal, terminal_state"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5020f74ead06516c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Get Reward, the reward is returned at the end of an episode\n",
    "def get_reward(new_state, time_step, action, xdata, signal, terminal_state, epoch=0):\n",
    "    reward = 0\n",
    "    signal.fillna(value=0, inplace=True)\n",
    "    if terminal_state == 0:\n",
    "        #get reward for the most current action\n",
    "        if signal[time_step] != signal[time_step-1] and terminal_state == 0:\n",
    "            i=1\n",
    "            while signal[time_step-i] == signal[time_step-1-i] and time_step - 1 - i > 0:\n",
    "                i += 1\n",
    "            reward = (xdata[time_step-1, 0] - xdata[time_step - i-1, 0]) * signal[time_step - 1]*-100 + i*np.abs(signal[time_step - 1])/10.0\n",
    "        if signal[time_step] == 0 and signal[time_step - 1] == 0:\n",
    "            reward -= 10\n",
    "\n",
    "    #calculate the reward for all actions if the last iteration in set\n",
    "    if terminal_state == 1:\n",
    "        #run backtest, send list of trade signals and asset data to backtest function\n",
    "        bt = twp.Backtest(pd.Series(data=[x[0] for x in xdata]), signal, signalType='shares')\n",
    "        reward = bt.pnl.iloc[-1]\n",
    "\n",
    "    return reward"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f89c76cc1925bd01",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_Q(eval_data, eval_model):\n",
    "    #This function is used to evaluate the perofrmance of the system each epoch, without the influence of epsilon and random actions\n",
    "    signal = pd.Series(index=np.arange(len(eval_data)))\n",
    "    state, xdata = init_state(eval_data)\n",
    "    status = 1\n",
    "    terminal_state = 0\n",
    "    time_step = 1\n",
    "    while(status == 1):\n",
    "        #We start in state S\n",
    "        #Run the Q function on S to get predicted reward values on all the possible actions\n",
    "        qval = eval_model.predict(state.reshape(1,2), batch_size=1)\n",
    "        action = (np.argmax(qval))\n",
    "        #Take action, observe new state S'\n",
    "        new_state, time_step, signal, terminal_state = take_action(state, xdata, action, signal, time_step)\n",
    "        #Observe reward\n",
    "        eval_reward = get_reward(new_state, time_step, action, xdata, signal, terminal_state, i)\n",
    "        state = new_state\n",
    "        if terminal_state == 1: #terminal state\n",
    "            status = 0\n",
    "    return eval_reward"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "af27f7d702b78ddd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This neural network is the Q-function, run it like this:\n",
    "#model.predict(state.reshape(1,64), batch_size=1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='lecun_uniform', input_shape=(2,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2)) I'm not using dropout in this example\n",
    "\n",
    "model.add(Dense(4, kernel_initializer='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(4, kernel_initializer='lecun_uniform'))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='mse', optimizer=rms)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "185fda39bc7d19df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random, timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "indata = load_data(type_evol='random_walk')\n",
    "epochs = 100\n",
    "gamma = 0.9 #a high gamma makes a long-term reward more valuable\n",
    "epsilon = 1\n",
    "learning_progress = []\n",
    "#stores tuples of (S, A, R, S')\n",
    "h = 0\n",
    "signal = pd.Series(index=np.arange(len(indata)))\n",
    "for i in range(epochs):\n",
    "\n",
    "    state, xdata = init_state(indata)\n",
    "    status = 1\n",
    "    terminal_state = 0\n",
    "    time_step = 1\n",
    "    #while learning is still in progress\n",
    "    while(status == 1):\n",
    "        #We start in state S\n",
    "        #Run the Q function on S to get predicted reward values on all the possible actions\n",
    "        qval = model.predict(state.reshape(1,2), batch_size=1)\n",
    "        if (random.random() < epsilon) and i != epochs - 1: #maybe choose random action if not the last epoch\n",
    "            action = np.random.randint(0,4) #assumes 4 different actions\n",
    "        else: #choose best action from Q(s,a) values\n",
    "            action = (np.argmax(qval))\n",
    "        #Take action, observe new state S'\n",
    "        new_state, time_step, signal, terminal_state = take_action(state, xdata, action, signal, time_step)\n",
    "        #Observe reward\n",
    "        reward = get_reward(new_state, time_step, action, xdata, signal, terminal_state, i)\n",
    "        #Get max_Q(S',a)\n",
    "        newQ = model.predict(new_state.reshape(1,2), batch_size=1)\n",
    "        maxQ = np.max(newQ)\n",
    "        y = np.zeros((1,4))\n",
    "        y[:] = qval[:]\n",
    "        if terminal_state == 0: #non-terminal state\n",
    "            update = (reward + (gamma * maxQ))\n",
    "        else: #terminal state (means that it is the last state)\n",
    "            update = reward\n",
    "        y[0][action] = update #target output\n",
    "        model.fit(state.reshape(1,2), y, batch_size=1, epochs=1, verbose=0)\n",
    "        state = new_state\n",
    "        if terminal_state == 1: #terminal state\n",
    "            status = 0\n",
    "    eval_reward = evaluate_Q(indata, model)\n",
    "    print(\"Epoch #: %s Reward: %f Epsilon: %f\" % (i,eval_reward, epsilon))\n",
    "    learning_progress.append((eval_reward))\n",
    "    if epsilon > 0.1:\n",
    "        epsilon -= (1.0/epochs)\n",
    "\n",
    "elapsed = np.round(timeit.default_timer() - start_time, decimals=2)\n",
    "print(\"Completed in %f\" % (elapsed,))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a643c3fefd482836",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#plot results\n",
    "bt = twp.Backtest(pd.Series(data=[x[0] for x in xdata]), signal, signalType='shares')\n",
    "bt.data['delta'] = bt.data['shares'].diff().fillna(0)\n",
    "\n",
    "print(bt.data)\n",
    "\n",
    "plt.figure()\n",
    "bt.plotTrades()\n",
    "plt.suptitle('epoch' + str(i))\n",
    "# plt.savefig('plt/final_trades'+'.png', bbox_inches='tight', pad_inches=1, dpi=72) #assumes there is a ./plt dir\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "bt.plotTrades()\n",
    "plt.subplot(3,1,2)\n",
    "bt.pnl.plot(style='x-')\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(learning_progress)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e121419624e50fa0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c878ed86d907330d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
